--- a/cipher/camellia-aarch64.S	1697702010.000000000
+++ b/cipher/camellia-aarch64.S	1705151023.200693531
@@ -19,6 +19,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__)
@@ -197,10 +198,10 @@
 	eor YR, YR, RT1; \
 	str_output_be(RDST, YL, YR, XL, XR, RT0, RT1);
 
-.globl _gcry_camellia_arm_encrypt_block
-ELF(.type   _gcry_camellia_arm_encrypt_block,@function;)
+.globl C_SYMBOL_NAME(_gcry_camellia_arm_encrypt_block)
+ELF(.type   C_SYMBOL_NAME(_gcry_camellia_arm_encrypt_block),@function;)
 
-_gcry_camellia_arm_encrypt_block:
+C_SYMBOL_NAME(_gcry_camellia_arm_encrypt_block):
 	CFI_STARTPROC()
 	stp x19, x30, [sp, #-16]!
 	CFI_ADJUST_CFA_OFFSET(16)
@@ -214,7 +215,7 @@ _gcry_camellia_arm_encrypt_block:
 	 *	w3: keybitlen
 	 */
 
-	adr RTAB1,  _gcry_camellia_arm_tables;
+	adr RTAB1,  C_SYMBOL_NAME(_gcry_camellia_arm_tables);
 	mov RMASK, #(0xff<<4); /* byte mask */
 	add RTAB2, RTAB1, #(1 * 4);
 	add RTAB3, RTAB1, #(2 * 4);
@@ -255,12 +256,12 @@ _gcry_camellia_arm_encrypt_block:
 	ret_spec_stop;
 	CFI_ENDPROC()
 .ltorg
-ELF(.size _gcry_camellia_arm_encrypt_block,.-_gcry_camellia_arm_encrypt_block;)
+ELF(.size C_SYMBOL_NAME(_gcry_camellia_arm_encrypt_block),.-C_SYMBOL_NAME(_gcry_camellia_arm_encrypt_block);)
 
-.globl _gcry_camellia_arm_decrypt_block
-ELF(.type   _gcry_camellia_arm_decrypt_block,@function;)
+.globl C_SYMBOL_NAME(_gcry_camellia_arm_decrypt_block)
+ELF(.type   C_SYMBOL_NAME(_gcry_camellia_arm_decrypt_block),@function;)
 
-_gcry_camellia_arm_decrypt_block:
+C_SYMBOL_NAME(_gcry_camellia_arm_decrypt_block):
 	CFI_STARTPROC()
 	stp x19, x30, [sp, #-16]!
 	CFI_ADJUST_CFA_OFFSET(16)
@@ -274,7 +275,7 @@ _gcry_camellia_arm_decrypt_block:
 	 *	w3: keybitlen
 	 */
 
-	adr RTAB1,  _gcry_camellia_arm_tables;
+	adr RTAB1,  C_SYMBOL_NAME(_gcry_camellia_arm_tables);
 	mov RMASK, #(0xff<<4); /* byte mask */
 	add RTAB2, RTAB1, #(1 * 4);
 	add RTAB3, RTAB1, #(2 * 4);
@@ -311,12 +312,12 @@ _gcry_camellia_arm_decrypt_block:
 	b .Ldec_128;
 	CFI_ENDPROC()
 .ltorg
-ELF(.size _gcry_camellia_arm_decrypt_block,.-_gcry_camellia_arm_decrypt_block;)
+ELF(.size C_SYMBOL_NAME(_gcry_camellia_arm_decrypt_block),.-C_SYMBOL_NAME(_gcry_camellia_arm_decrypt_block);)
 
 /* Encryption/Decryption tables */
-ELF(.type  _gcry_camellia_arm_tables,@object;)
+ELF(.type  C_SYMBOL_NAME(_gcry_camellia_arm_tables),@object;)
 .balign 32
-_gcry_camellia_arm_tables:
+C_SYMBOL_NAME(_gcry_camellia_arm_tables):
 .Lcamellia_sp1110:
 .long 0x70707000
 .Lcamellia_sp0222:
@@ -580,7 +581,7 @@ _gcry_camellia_arm_tables:
 .long 0xc7c7c700, 0x008f8f8f, 0xe300e3e3, 0xf4f400f4
 .long 0x80808000, 0x00010101, 0x40004040, 0xc7c700c7
 .long 0x9e9e9e00, 0x003d3d3d, 0x4f004f4f, 0x9e9e009e
-ELF(.size _gcry_camellia_arm_tables,.-_gcry_camellia_arm_tables;)
+ELF(.size C_SYMBOL_NAME(_gcry_camellia_arm_tables),.-C_SYMBOL_NAME(_gcry_camellia_arm_tables);)
 
 #endif /*HAVE_COMPATIBLE_GCC_AARCH64_PLATFORM_AS*/
 #endif /*__AARCH64EL__*/
--- a/cipher/chacha20-aarch64.S	1697702010.000000000
+++ b/cipher/chacha20-aarch64.S	1705216082.440915965
@@ -27,6 +27,7 @@
  * Public domain.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -181,23 +182,23 @@
 			_(iop27), _(iop28), _(iop29));
 
 .align 4
-.globl _gcry_chacha20_aarch64_blocks4_data_inc_counter
-_gcry_chacha20_aarch64_blocks4_data_inc_counter:
+.globl C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_inc_counter)
+C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_inc_counter):
 	.long 0,1,2,3
 
 .align 4
-.globl _gcry_chacha20_aarch64_blocks4_data_rot8
-_gcry_chacha20_aarch64_blocks4_data_rot8:
+.globl C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_rot8)
+C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_rot8):
 	.byte 3,0,1,2
 	.byte 7,4,5,6
 	.byte 11,8,9,10
 	.byte 15,12,13,14
 
 .align 3
-.globl _gcry_chacha20_aarch64_blocks4
-ELF(.type _gcry_chacha20_aarch64_blocks4,%function;)
+.globl C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4)
+ELF(.type C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4),%function;)
 
-_gcry_chacha20_aarch64_blocks4:
+C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4):
 	/* input:
 	 *	x0: input
 	 *	x1: dst
@@ -206,10 +207,10 @@ _gcry_chacha20_aarch64_blocks4:
 	 */
 	CFI_STARTPROC()
 
-	GET_DATA_POINTER(CTR, _gcry_chacha20_aarch64_blocks4_data_rot8);
+	GET_DATA_POINTER(CTR, C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_rot8));
 	add INPUT_CTR, INPUT, #(12*4);
 	ld1 {ROT8.16b}, [CTR];
-	GET_DATA_POINTER(CTR, _gcry_chacha20_aarch64_blocks4_data_inc_counter);
+	GET_DATA_POINTER(CTR, C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_inc_counter));
 	mov INPUT_POS, INPUT;
 	ld1 {VCTR.16b}, [CTR];
 
@@ -358,17 +359,17 @@ _gcry_chacha20_aarch64_blocks4:
 	eor x0, x0, x0
 	ret_spec_stop
 	CFI_ENDPROC()
-ELF(.size _gcry_chacha20_aarch64_blocks4, .-_gcry_chacha20_aarch64_blocks4;)
+ELF(.size C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4), .-C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4);)
 
 /**********************************************************************
   4-way stitched chacha20-poly1305
  **********************************************************************/
 
 .align 3
-.globl _gcry_chacha20_poly1305_aarch64_blocks4
-ELF(.type _gcry_chacha20_poly1305_aarch64_blocks4,%function;)
+.globl C_SYMBOL_NAME(_gcry_chacha20_poly1305_aarch64_blocks4)
+ELF(.type C_SYMBOL_NAME(_gcry_chacha20_poly1305_aarch64_blocks4),%function;)
 
-_gcry_chacha20_poly1305_aarch64_blocks4:
+C_SYMBOL_NAME(_gcry_chacha20_poly1305_aarch64_blocks4):
 	/* input:
 	 *	x0: input
 	 *	x1: dst
@@ -383,10 +384,10 @@ _gcry_chacha20_poly1305_aarch64_blocks4:
 	mov POLY_RSTATE, x4;
 	mov POLY_RSRC, x5;
 
-	GET_DATA_POINTER(CTR, _gcry_chacha20_aarch64_blocks4_data_rot8);
+	GET_DATA_POINTER(CTR, C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_rot8));
 	add INPUT_CTR, INPUT, #(12*4);
 	ld1 {ROT8.16b}, [CTR];
-	GET_DATA_POINTER(CTR, _gcry_chacha20_aarch64_blocks4_data_inc_counter);
+	GET_DATA_POINTER(CTR, C_SYMBOL_NAME(_gcry_chacha20_aarch64_blocks4_data_inc_counter));
 	mov INPUT_POS, INPUT;
 	ld1 {VCTR.16b}, [CTR];
 
@@ -643,6 +644,6 @@ _gcry_chacha20_poly1305_aarch64_blocks4:
 	POLY1305_POP_REGS()
 	ret_spec_stop
 	CFI_ENDPROC()
-ELF(.size _gcry_chacha20_poly1305_aarch64_blocks4, .-_gcry_chacha20_poly1305_aarch64_blocks4;)
+ELF(.size C_SYMBOL_NAME(_gcry_chacha20_poly1305_aarch64_blocks4), .-C_SYMBOL_NAME(_gcry_chacha20_poly1305_aarch64_blocks4);)
 
 #endif
--- a/cipher/cipher-gcm-armv8-aarch64-ce.S	1697702010.000000000
+++ b/cipher/cipher-gcm-armv8-aarch64-ce.S	1705216606.527742084
@@ -17,6 +17,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -177,9 +178,9 @@ gcry_gcm_reduction_constant:
  *                                          void *gcm_table);
  */
 .align 3
-.globl _gcry_ghash_armv8_ce_pmull
-ELF(.type  _gcry_ghash_armv8_ce_pmull,%function;)
-_gcry_ghash_armv8_ce_pmull:
+.globl C_SYMBOL_NAME(_gcry_ghash_armv8_ce_pmull)
+ELF(.type  C_SYMBOL_NAME(_gcry_ghash_armv8_ce_pmull),%function;)
+C_SYMBOL_NAME(_gcry_ghash_armv8_ce_pmull):
   /* input:
    *    x0: gcm_key
    *    x1: result/hash
@@ -367,7 +368,7 @@ _gcry_ghash_armv8_ce_pmull:
   mov x0, #0
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_ghash_armv8_ce_pmull,.-_gcry_ghash_armv8_ce_pmull;)
+ELF(.size C_SYMBOL_NAME(_gcry_ghash_armv8_ce_pmull),.-C_SYMBOL_NAME(_gcry_ghash_armv8_ce_pmull);)
 
 
 /*
@@ -376,9 +377,9 @@ ELF(.size _gcry_ghash_armv8_ce_pmull,.-_
  *                                            void *gcm_table);
  */
 .align 3
-.globl _gcry_polyval_armv8_ce_pmull
-ELF(.type  _gcry_polyval_armv8_ce_pmull,%function;)
-_gcry_polyval_armv8_ce_pmull:
+.globl C_SYMBOL_NAME(_gcry_polyval_armv8_ce_pmull)
+ELF(.type  C_SYMBOL_NAME(_gcry_polyval_armv8_ce_pmull),%function;)
+C_SYMBOL_NAME(_gcry_polyval_armv8_ce_pmull):
   /* input:
    *    x0: gcm_key
    *    x1: result/hash
@@ -595,16 +596,16 @@ _gcry_polyval_armv8_ce_pmull:
   mov x0, #0
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_polyval_armv8_ce_pmull,.-_gcry_polyval_armv8_ce_pmull;)
+ELF(.size C_SYMBOL_NAME(_gcry_polyval_armv8_ce_pmull),.-C_SYMBOL_NAME(_gcry_polyval_armv8_ce_pmull);)
 
 
 /*
  * void _gcry_ghash_setup_armv8_ce_pmull (void *gcm_key, void *gcm_table);
  */
 .align 3
-.globl _gcry_ghash_setup_armv8_ce_pmull
-ELF(.type  _gcry_ghash_setup_armv8_ce_pmull,%function;)
-_gcry_ghash_setup_armv8_ce_pmull:
+.globl C_SYMBOL_NAME(_gcry_ghash_setup_armv8_ce_pmull)
+ELF(.type  C_SYMBOL_NAME(_gcry_ghash_setup_armv8_ce_pmull),%function;)
+C_SYMBOL_NAME(_gcry_ghash_setup_armv8_ce_pmull):
   /* input:
    *	x0: gcm_key
    *	x1: gcm_table
@@ -647,6 +648,6 @@ _gcry_ghash_setup_armv8_ce_pmull:
 
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_ghash_setup_armv8_ce_pmull,.-_gcry_ghash_setup_armv8_ce_pmull;)
+ELF(.size C_SYMBOL_NAME(_gcry_ghash_setup_armv8_ce_pmull),.-C_SYMBOL_NAME(_gcry_ghash_setup_armv8_ce_pmull);)
 
 #endif
--- a/cipher/crc-armv8-aarch64-ce.S	1697702010.000000000
+++ b/cipher/crc-armv8-aarch64-ce.S	1705150528.771633650
@@ -17,6 +17,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -60,9 +61,9 @@
  *                                  const struct crc32_consts_s *consts);
  */
 .align 3
-.globl _gcry_crc32r_armv8_ce_bulk
-ELF(.type  _gcry_crc32r_armv8_ce_bulk,%function;)
-_gcry_crc32r_armv8_ce_bulk:
+.globl C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_bulk)
+ELF(.type  C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_bulk),%function;)
+C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_bulk):
   /* input:
    *    x0: pcrc
    *    x1: inbuf
@@ -168,10 +169,33 @@ _gcry_crc32r_armv8_ce_bulk:
   b.eq .Lcrc32r_final_fold
 
   /* Partial fold. */
-
+#if !__APPLE__
   add x4, x7, #.Lcrc32_refl_shuf_shift - .Lcrc32_constants
   add x5, x7, #.Lcrc32_refl_shuf_shift - .Lcrc32_constants + 16
   add x6, x7, #.Lcrc32_partial_fold_input_mask - .Lcrc32_constants
+#else
+/*
+ldr x8, =.Lcrc32_refl_shuf_shift
+ldr x9, =.Lcrc32_constants
+sub x4, x8, x9
+add x4, x7, x4
+
+ldr x8, =.Lcrc32_refl_shuf_shift
+ldr x9, =.Lcrc32_constants
+add x8, x8, #16
+sub x5, x8, x9
+add x5, x7, x5
+
+ldr x8, =.Lcrc32_partial_fold_input_mask
+ldr x9, =.Lcrc32_constants
+sub x6, x8, x9
+add x6, x7, x6
+*/
+  adr x4, .Lcrc32_refl_shuf_shift
+  adr x5, .Lcrc32_refl_shuf_shift
+  add x5, x5, #16
+  adr x6, .Lcrc32_partial_fold_input_mask
+#endif
   sub x8, x2, #16
   add x4, x4, x2
   add x5, x5, x2
@@ -229,16 +253,16 @@ _gcry_crc32r_armv8_ce_bulk:
 
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_crc32r_armv8_ce_bulk,.-_gcry_crc32r_armv8_ce_bulk;)
+ELF(.size C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_bulk),.-C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_bulk);)
 
 /*
  * void _gcry_crc32r_armv8_ce_reduction_4 (u32 *pcrc, u32 data, u32 crc,
  *                                         const struct crc32_consts_s *consts);
  */
 .align 3
-.globl _gcry_crc32r_armv8_ce_reduction_4
-ELF(.type  _gcry_crc32r_armv8_ce_reduction_4,%function;)
-_gcry_crc32r_armv8_ce_reduction_4:
+.globl C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_reduction_4)
+ELF(.type  C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_reduction_4),%function;)
+C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_reduction_4):
   /* input:
    *    w0: data
    *    w1: crc
@@ -262,16 +286,16 @@ _gcry_crc32r_armv8_ce_reduction_4:
 
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_crc32r_armv8_ce_reduction_4,.-_gcry_crc32r_armv8_ce_reduction_4;)
+ELF(.size C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_reduction_4),.-C_SYMBOL_NAME(_gcry_crc32r_armv8_ce_reduction_4);)
 
 /*
  * void _gcry_crc32_armv8_ce_bulk (u32 *pcrc, const byte *inbuf, size_t inlen,
  *                                 const struct crc32_consts_s *consts);
  */
 .align 3
-.globl _gcry_crc32_armv8_ce_bulk
-ELF(.type  _gcry_crc32_armv8_ce_bulk,%function;)
-_gcry_crc32_armv8_ce_bulk:
+.globl C_SYMBOL_NAME(_gcry_crc32_armv8_ce_bulk)
+ELF(.type  C_SYMBOL_NAME(_gcry_crc32_armv8_ce_bulk),%function;)
+C_SYMBOL_NAME(_gcry_crc32_armv8_ce_bulk):
   /* input:
    *    x0: pcrc
    *    x1: inbuf
@@ -281,7 +305,17 @@ _gcry_crc32_armv8_ce_bulk:
   CFI_STARTPROC()
 
   GET_DATA_POINTER(x7, .Lcrc32_constants)
+#if !__APPLE__
   add x4, x7, #.Lcrc32_bswap_shuf - .Lcrc32_constants
+#else
+/*
+  ldr x8, =.Lcrc32_refl_shuf_shift
+  ldr x9, =.Lcrc32_constants
+  sub x4, x8, x9
+  add x4, x7, x4
+*/
+  adr x4, .Lcrc32_bswap_shuf
+#endif
   cmp x2, #128
   ld1 {v7.16b}, [x4]
 
@@ -393,10 +427,35 @@ _gcry_crc32_armv8_ce_bulk:
   b.eq .Lcrc32_final_fold
 
   /* Partial fold. */
-
+#if !__APPLE__
   add x4, x7, #.Lcrc32_refl_shuf_shift - .Lcrc32_constants + 32
   add x5, x7, #.Lcrc32_shuf_shift - .Lcrc32_constants + 16
   add x6, x7, #.Lcrc32_partial_fold_input_mask - .Lcrc32_constants
+#else
+/*
+  ldr x8, =.Lcrc32_refl_shuf_shift
+  ldr x9, =.Lcrc32_constants
+  add x8, x8, #32
+  sub x4, x8, x9
+  add x4, x7, x4
+
+  ldr x8, =.Lcrc32_refl_shuf_shift
+  ldr x9, =.Lcrc32_constants
+  add x8, x8, #16
+  sub x5, x8, x9
+  add x5, x7, x5
+
+  ldr x8, =.Lcrc32_partial_fold_input_mask
+  ldr x9, =.Lcrc32_constants
+  sub x6, x8, x9
+  add x5, x7, x5
+*/
+  adr x4, .Lcrc32_refl_shuf_shift
+  add x4, x4, #32
+  adr x5, .Lcrc32_shuf_shift
+  add x5, x5, #16
+  adr x6, .Lcrc32_partial_fold_input_mask
+#endif
   sub x8, x2, #16
   sub x4, x4, x2
   add x5, x5, x2
@@ -459,16 +518,16 @@ _gcry_crc32_armv8_ce_bulk:
 
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_crc32_armv8_ce_bulk,.-_gcry_crc32_armv8_ce_bulk;)
+ELF(.size C_SYMBOL_NAME(_gcry_crc32_armv8_ce_bulk),.-C_SYMBOL_NAME(_gcry_crc32_armv8_ce_bulk);)
 
 /*
  * void _gcry_crc32_armv8_ce_reduction_4 (u32 *pcrc, u32 data, u32 crc,
  *                                        const struct crc32_consts_s *consts);
  */
 .align 3
-.globl _gcry_crc32_armv8_ce_reduction_4
-ELF(.type  _gcry_crc32_armv8_ce_reduction_4,%function;)
-_gcry_crc32_armv8_ce_reduction_4:
+.globl C_SYMBOL_NAME(_gcry_crc32_armv8_ce_reduction_4)
+ELF(.type  C_SYMBOL_NAME(_gcry_crc32_armv8_ce_reduction_4),%function;)
+C_SYMBOL_NAME(_gcry_crc32_armv8_ce_reduction_4):
   /* input:
    *    w0: data
    *    w1: crc
@@ -492,6 +551,6 @@ _gcry_crc32_armv8_ce_reduction_4:
 
   ret_spec_stop
   CFI_ENDPROC()
-ELF(.size _gcry_crc32_armv8_ce_reduction_4,.-_gcry_crc32_armv8_ce_reduction_4;)
+ELF(.size C_SYMBOL_NAME(_gcry_crc32_armv8_ce_reduction_4),.-C_SYMBOL_NAME(_gcry_crc32_armv8_ce_reduction_4);)
 
 #endif
--- a/cipher/rijndael-aarch64.S	1697702010.000000000
+++ b/cipher/rijndael-aarch64.S	1705149349.979665715
@@ -18,6 +18,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__)
@@ -205,10 +206,10 @@
 	do_lastencround(ra, rb, rc, rd, rna, rnb, rnc, rnd); \
 	addroundkey(rna, rnb, rnc, rnd, ra, rb, rc, rd, dummy);
 
-.globl _gcry_aes_arm_encrypt_block
-ELF(.type   _gcry_aes_arm_encrypt_block,%function;)
-
-_gcry_aes_arm_encrypt_block:
+.globl C_SYMBOL_NAME(_gcry_aes_arm_encrypt_block)
+ELF(.type   C_SYMBOL_NAME(_gcry_aes_arm_encrypt_block),%function;)
+.align 2
+C_SYMBOL_NAME(_gcry_aes_arm_encrypt_block):
 	/* input:
 	 *	%x0: keysched, CTX
 	 *	%x1: dst
@@ -287,7 +288,7 @@ _gcry_aes_arm_encrypt_block:
 
 	b .Lenc_done;
 	CFI_ENDPROC();
-ELF(.size _gcry_aes_arm_encrypt_block,.-_gcry_aes_arm_encrypt_block;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_arm_encrypt_block),.-C_SYMBOL_NAME(_gcry_aes_arm_encrypt_block);)
 
 #define addroundkey_dec(round, ra, rb, rc, rd, rna, rnb, rnc, rnd) \
 	ldr rna, [CTX, #(((round) * 16) + 0 * 4)]; \
@@ -430,10 +431,10 @@ ELF(.size _gcry_aes_arm_encrypt_block,.-
 	do_lastdecround(ra, rb, rc, rd, rna, rnb, rnc, rnd); \
 	addroundkey(rna, rnb, rnc, rnd, ra, rb, rc, rd, dummy);
 
-.globl _gcry_aes_arm_decrypt_block
-ELF(.type   _gcry_aes_arm_decrypt_block,%function;)
-
-_gcry_aes_arm_decrypt_block:
+.globl C_SYMBOL_NAME(_gcry_aes_arm_decrypt_block)
+ELF(.type   C_SYMBOL_NAME(_gcry_aes_arm_decrypt_block),%function;)
+.align 2
+C_SYMBOL_NAME(_gcry_aes_arm_decrypt_block):
 	/* input:
 	 *	%x0: keysched, CTX
 	 *	%x1: dst
@@ -508,7 +509,7 @@ _gcry_aes_arm_decrypt_block:
 
 	b .Ldec_tail;
 	CFI_ENDPROC();
-ELF(.size _gcry_aes_arm_decrypt_block,.-_gcry_aes_arm_decrypt_block;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_arm_decrypt_block),.-C_SYMBOL_NAME(_gcry_aes_arm_decrypt_block);)
 
 #endif /*HAVE_COMPATIBLE_GCC_AARCH64_PLATFORM_AS*/
 #endif /*__AARCH64EL__ */
--- a/cipher/rijndael-armv8-aarch64-ce.S	1697702010.000000000
+++ b/cipher/rijndael-armv8-aarch64-ce.S	1705218172.512838647
@@ -17,6 +17,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -263,9 +264,9 @@
  *                                     unsigned int nrounds);
  */
 .align 3
-.globl _gcry_aes_enc_armv8_ce
-ELF(.type  _gcry_aes_enc_armv8_ce,%function;)
-_gcry_aes_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_enc_armv8_ce)
+ELF(.type C_SYMBOL_NAME(_gcry_aes_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_enc_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: dst
@@ -318,7 +319,7 @@ _gcry_aes_enc_armv8_ce:
   CLEAR_REG(vk13)
   b .Lenc1_tail
   CFI_ENDPROC();
-ELF(.size _gcry_aes_enc_armv8_ce,.-_gcry_aes_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_enc_armv8_ce);)
 
 
 /*
@@ -327,9 +328,9 @@ ELF(.size _gcry_aes_enc_armv8_ce,.-_gcry
  *                                     unsigned int nrounds);
  */
 .align 3
-.globl _gcry_aes_dec_armv8_ce
-ELF(.type  _gcry_aes_dec_armv8_ce,%function;)
-_gcry_aes_dec_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_dec_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_dec_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_dec_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: dst
@@ -382,7 +383,7 @@ _gcry_aes_dec_armv8_ce:
   CLEAR_REG(vk13)
   b .Ldec1_tail
   CFI_ENDPROC();
-ELF(.size _gcry_aes_dec_armv8_ce,.-_gcry_aes_dec_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_dec_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_dec_armv8_ce);)
 
 
 /*
@@ -394,9 +395,9 @@ ELF(.size _gcry_aes_dec_armv8_ce,.-_gcry
  */
 
 .align 3
-.globl _gcry_aes_cbc_enc_armv8_ce
-ELF(.type  _gcry_aes_cbc_enc_armv8_ce,%function;)
-_gcry_aes_cbc_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_cbc_enc_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_cbc_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_cbc_enc_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: outbuf
@@ -465,7 +466,7 @@ _gcry_aes_cbc_enc_armv8_ce:
 .Lcbc_enc_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_cbc_enc_armv8_ce,.-_gcry_aes_cbc_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_cbc_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_cbc_enc_armv8_ce);)
 
 /*
  * void _gcry_aes_cbc_dec_armv8_ce (const void *keysched,
@@ -475,9 +476,9 @@ ELF(.size _gcry_aes_cbc_enc_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_cbc_dec_armv8_ce
-ELF(.type  _gcry_aes_cbc_dec_armv8_ce,%function;)
-_gcry_aes_cbc_dec_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_cbc_dec_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_cbc_dec_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_cbc_dec_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: outbuf
@@ -586,7 +587,7 @@ _gcry_aes_cbc_dec_armv8_ce:
 .Lcbc_dec_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_cbc_dec_armv8_ce,.-_gcry_aes_cbc_dec_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_cbc_dec_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_cbc_dec_armv8_ce);)
 
 
 /*
@@ -597,9 +598,9 @@ ELF(.size _gcry_aes_cbc_dec_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_ctr_enc_armv8_ce
-ELF(.type  _gcry_aes_ctr_enc_armv8_ce,%function;)
-_gcry_aes_ctr_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_ctr_enc_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_ctr_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_ctr_enc_armv8_ce):
   /* input:
    *    r0: keysched
    *    r1: outbuf
@@ -779,7 +780,7 @@ _gcry_aes_ctr_enc_armv8_ce:
 .Lctr_enc_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_ctr_enc_armv8_ce,.-_gcry_aes_ctr_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_ctr_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_ctr_enc_armv8_ce);)
 
 
 /*
@@ -791,9 +792,9 @@ ELF(.size _gcry_aes_ctr_enc_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_ctr32le_enc_armv8_ce
-ELF(.type  _gcry_aes_ctr32le_enc_armv8_ce,%function;)
-_gcry_aes_ctr32le_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_ctr32le_enc_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_ctr32le_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_ctr32le_enc_armv8_ce):
   /* input:
    *    r0: keysched
    *    r1: outbuf
@@ -926,7 +927,7 @@ _gcry_aes_ctr32le_enc_armv8_ce:
 .Lctr32le_enc_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_ctr32le_enc_armv8_ce,.-_gcry_aes_ctr32le_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_ctr32le_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_ctr32le_enc_armv8_ce);)
 
 
 /*
@@ -937,9 +938,9 @@ ELF(.size _gcry_aes_ctr32le_enc_armv8_ce
  */
 
 .align 3
-.globl _gcry_aes_cfb_enc_armv8_ce
-ELF(.type  _gcry_aes_cfb_enc_armv8_ce,%function;)
-_gcry_aes_cfb_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_cfb_enc_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_cfb_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_cfb_enc_armv8_ce):
   /* input:
    *    r0: keysched
    *    r1: outbuf
@@ -1008,7 +1009,7 @@ _gcry_aes_cfb_enc_armv8_ce:
 .Lcfb_enc_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_cfb_enc_armv8_ce,.-_gcry_aes_cfb_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_cfb_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_cfb_enc_armv8_ce);)
 
 
 /*
@@ -1019,9 +1020,9 @@ ELF(.size _gcry_aes_cfb_enc_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_cfb_dec_armv8_ce
-ELF(.type  _gcry_aes_cfb_dec_armv8_ce,%function;)
-_gcry_aes_cfb_dec_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_cfb_dec_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_cfb_dec_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_cfb_dec_armv8_ce):
   /* input:
    *    r0: keysched
    *    r1: outbuf
@@ -1132,7 +1133,7 @@ _gcry_aes_cfb_dec_armv8_ce:
 .Lcfb_dec_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_cfb_dec_armv8_ce,.-_gcry_aes_cfb_dec_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_cfb_dec_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_cfb_dec_armv8_ce);)
 
 
 /*
@@ -1148,9 +1149,9 @@ ELF(.size _gcry_aes_cfb_dec_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_ocb_enc_armv8_ce
-ELF(.type  _gcry_aes_ocb_enc_armv8_ce,%function;)
-_gcry_aes_ocb_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_ocb_enc_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_ocb_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_ocb_enc_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: outbuf
@@ -1381,7 +1382,7 @@ _gcry_aes_ocb_enc_armv8_ce:
 
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_ocb_enc_armv8_ce,.-_gcry_aes_ocb_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_ocb_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_ocb_enc_armv8_ce);)
 
 
 /*
@@ -1397,9 +1398,9 @@ ELF(.size _gcry_aes_ocb_enc_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_ocb_dec_armv8_ce
-ELF(.type  _gcry_aes_ocb_dec_armv8_ce,%function;)
-_gcry_aes_ocb_dec_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_ocb_dec_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_ocb_dec_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_ocb_dec_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: outbuf
@@ -1460,7 +1461,7 @@ _gcry_aes_ocb_dec_armv8_ce:
 
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_ocb_dec_armv8_ce,.-_gcry_aes_ocb_dec_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_ocb_dec_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_ocb_dec_armv8_ce);)
 
 
 /*
@@ -1475,9 +1476,9 @@ ELF(.size _gcry_aes_ocb_dec_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_ocb_auth_armv8_ce
-ELF(.type  _gcry_aes_ocb_auth_armv8_ce,%function;)
-_gcry_aes_ocb_auth_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_ocb_auth_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_ocb_auth_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_ocb_auth_armv8_ce):
   /* input:
    *    x0: keysched
    *    x1: abuf
@@ -1607,7 +1608,7 @@ _gcry_aes_ocb_auth_armv8_ce:
 
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_ocb_auth_armv8_ce,.-_gcry_aes_ocb_auth_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_ocb_auth_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_ocb_auth_armv8_ce);)
 
 
 /*
@@ -1620,9 +1621,9 @@ ELF(.size _gcry_aes_ocb_auth_armv8_ce,.-
  */
 
 .align 3
-.globl _gcry_aes_xts_enc_armv8_ce
-ELF(.type  _gcry_aes_xts_enc_armv8_ce,%function;)
-_gcry_aes_xts_enc_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_xts_enc_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_xts_enc_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_xts_enc_armv8_ce):
   /* input:
    *    r0: keysched
    *    r1: outbuf
@@ -1808,7 +1809,7 @@ _gcry_aes_xts_enc_armv8_ce:
 .Lxts_enc_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_xts_enc_armv8_ce,.-_gcry_aes_xts_enc_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_xts_enc_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_xts_enc_armv8_ce);)
 
 
 /*
@@ -1821,9 +1822,9 @@ ELF(.size _gcry_aes_xts_enc_armv8_ce,.-_
  */
 
 .align 3
-.globl _gcry_aes_xts_dec_armv8_ce
-ELF(.type  _gcry_aes_xts_dec_armv8_ce,%function;)
-_gcry_aes_xts_dec_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_xts_dec_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_xts_dec_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_xts_dec_armv8_ce):
   /* input:
    *    r0: keysched
    *    r1: outbuf
@@ -1876,16 +1877,16 @@ _gcry_aes_xts_dec_armv8_ce:
 .Lxts_dec_skip:
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_xts_dec_armv8_ce,.-_gcry_aes_xts_dec_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_xts_dec_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_xts_dec_armv8_ce);)
 
 
 /*
  * u32 _gcry_aes_sbox4_armv8_ce(u32 in4b);
  */
 .align 3
-.globl _gcry_aes_sbox4_armv8_ce
-ELF(.type  _gcry_aes_sbox4_armv8_ce,%function;)
-_gcry_aes_sbox4_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_sbox4_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_sbox4_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_sbox4_armv8_ce):
   /* See "Gouvêa, C. P. L. & López, J. Implementing GCM on ARMv8. Topics in
    * Cryptology — CT-RSA 2015" for details.
    */
@@ -1899,16 +1900,16 @@ _gcry_aes_sbox4_armv8_ce:
   CLEAR_REG(v0)
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_sbox4_armv8_ce,.-_gcry_aes_sbox4_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_sbox4_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_sbox4_armv8_ce);)
 
 
 /*
  * void _gcry_aes_invmixcol_armv8_ce(void *dst, const void *src);
  */
 .align 3
-.globl _gcry_aes_invmixcol_armv8_ce
-ELF(.type  _gcry_aes_invmixcol_armv8_ce,%function;)
-_gcry_aes_invmixcol_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_aes_invmixcol_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_aes_invmixcol_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_aes_invmixcol_armv8_ce):
   CFI_STARTPROC();
   ld1 {v0.16b}, [x1]
   aesimc v0.16b, v0.16b
@@ -1916,6 +1917,6 @@ _gcry_aes_invmixcol_armv8_ce:
   CLEAR_REG(v0)
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_aes_invmixcol_armv8_ce,.-_gcry_aes_invmixcol_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_aes_invmixcol_armv8_ce),.-C_SYMBOL_NAME(_gcry_aes_invmixcol_armv8_ce);)
 
 #endif
--- a/cipher/sha1-armv8-aarch64-ce.S	1697702010.000000000
+++ b/cipher/sha1-armv8-aarch64-ce.S	1705216536.791226863
@@ -17,6 +17,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -97,9 +98,9 @@ gcry_sha1_aarch64_ce_K_VEC:
  *                                size_t nblks)
  */
 .align 3
-.globl _gcry_sha1_transform_armv8_ce
-ELF(.type  _gcry_sha1_transform_armv8_ce,%function;)
-_gcry_sha1_transform_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_sha1_transform_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_sha1_transform_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_sha1_transform_armv8_ce):
   /* input:
    *	x0: ctx, CTX
    *	x1: data (64*nblks bytes)
@@ -196,6 +197,6 @@ _gcry_sha1_transform_armv8_ce:
   mov x0, #0
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_sha1_transform_armv8_ce,.-_gcry_sha1_transform_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_sha1_transform_armv8_ce),.-C_SYMBOL_NAME(_gcry_sha1_transform_armv8_ce);)
 
 #endif
--- a/cipher/sha256-armv8-aarch64-ce.S	1697702010.000000000
+++ b/cipher/sha256-armv8-aarch64-ce.S	1705216505.764905602
@@ -17,6 +17,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -107,9 +108,9 @@ gcry_sha256_aarch64_ce_K:
  *                                  size_t num_blks)
  */
 .align 3
-.globl _gcry_sha256_transform_armv8_ce
-ELF(.type  _gcry_sha256_transform_armv8_ce,%function;)
-_gcry_sha256_transform_armv8_ce:
+.globl C_SYMBOL_NAME(_gcry_sha256_transform_armv8_ce)
+ELF(.type  C_SYMBOL_NAME(_gcry_sha256_transform_armv8_ce),%function;)
+C_SYMBOL_NAME(_gcry_sha256_transform_armv8_ce):
   /* input:
    *	r0: ctx, CTX
    *	r1: data (64*nblks bytes)
@@ -210,6 +211,6 @@ _gcry_sha256_transform_armv8_ce:
   mov x0, #0
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_sha256_transform_armv8_ce,.-_gcry_sha256_transform_armv8_ce;)
+ELF(.size C_SYMBOL_NAME(_gcry_sha256_transform_armv8_ce),.-C_SYMBOL_NAME(_gcry_sha256_transform_armv8_ce);)
 
 #endif
--- a/cipher/sm3-aarch64.S	1697702010.000000000
+++ b/cipher/sm3-aarch64.S	1705216710.607685558
@@ -18,6 +18,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__) && \
@@ -31,8 +32,8 @@
 
 .text
 .align 4
-ELF(.type _gcry_sm3_aarch64_consts,@object)
-_gcry_sm3_aarch64_consts:
+ELF(.type C_SYMBOL_NAME(_gcry_sm3_aarch64_consts),@object)
+C_SYMBOL_NAME(_gcry_sm3_aarch64_consts):
 .LKtable:
   .long 0x79cc4519, 0xf3988a32, 0xe7311465, 0xce6228cb
   .long 0x9cc45197, 0x3988a32f, 0x7311465e, 0xe6228cbc
@@ -50,7 +51,7 @@ _gcry_sm3_aarch64_consts:
   .long 0xd8a7a879, 0xb14f50f3, 0x629ea1e7, 0xc53d43ce
   .long 0x8a7a879d, 0x14f50f3b, 0x29ea1e76, 0x53d43cec
   .long 0xa7a879d8, 0x4f50f3b1, 0x9ea1e762, 0x3d43cec5
-ELF(.size _gcry_sm3_aarch64_consts,.-_gcry_sm3_aarch64_consts)
+ELF(.size C_SYMBOL_NAME(_gcry_sm3_aarch64_consts),.-C_SYMBOL_NAME(_gcry_sm3_aarch64_consts))
 
 /* Context structure */
 
@@ -391,9 +392,9 @@ ELF(.size _gcry_sm3_aarch64_consts,.-_gc
  *                              size_t nblks)
  */
 .align 3
-.globl _gcry_sm3_transform_aarch64
-ELF(.type _gcry_sm3_transform_aarch64,%function;)
-_gcry_sm3_transform_aarch64:
+.globl C_SYMBOL_NAME(_gcry_sm3_transform_aarch64)
+ELF(.type C_SYMBOL_NAME(_gcry_sm3_transform_aarch64),%function;)
+C_SYMBOL_NAME(_gcry_sm3_transform_aarch64):
   CFI_STARTPROC();
 
   ldp ra, rb, [RSTATE, #0];
@@ -652,6 +653,6 @@ _gcry_sm3_transform_aarch64:
   CFI_RESTORE(x29);
   ret_spec_stop
   CFI_ENDPROC();
-ELF(.size _gcry_sm3_transform_aarch64, .-_gcry_sm3_transform_aarch64;)
+ELF(.size C_SYMBOL_NAME(_gcry_sm3_transform_aarch64), .-C_SYMBOL_NAME(_gcry_sm3_transform_aarch64);)
 
 #endif
--- a/cipher/twofish-aarch64.S	1697702010.000000000
+++ b/cipher/twofish-aarch64.S	1705149358.772052497
@@ -18,6 +18,7 @@
  * License along with this program; if not, see <http://www.gnu.org/licenses/>.
  */
 
+#include "sysdep.h"
 #include "asm-common-aarch64.h"
 
 #if defined(__AARCH64EL__)
@@ -216,10 +217,10 @@
 	decrypt_round(RA, RB, RC, RD, (nc) * 2, ror1, 1); \
 	ror1(RD);
 
-.globl _gcry_twofish_arm_encrypt_block
-ELF(.type   _gcry_twofish_arm_encrypt_block,%function;)
-
-_gcry_twofish_arm_encrypt_block:
+.globl C_SYMBOL_NAME(_gcry_twofish_arm_encrypt_block)
+ELF(.type   C_SYMBOL_NAME(_gcry_twofish_arm_encrypt_block),%function;)
+.align 2
+C_SYMBOL_NAME(_gcry_twofish_arm_encrypt_block):
 	/* input:
 	 *	x0: ctx
 	 *	x1: dst
@@ -265,12 +266,12 @@ _gcry_twofish_arm_encrypt_block:
 	ret_spec_stop;
 	CFI_ENDPROC();
 .ltorg
-ELF(.size _gcry_twofish_arm_encrypt_block,.-_gcry_twofish_arm_encrypt_block;)
-
-.globl _gcry_twofish_arm_decrypt_block
-ELF(.type   _gcry_twofish_arm_decrypt_block,%function;)
+ELF(.size C_SYMBOL_NAME(_gcry_twofish_arm_encrypt_block),.-C_SYMBOL_NAME(_gcry_twofish_arm_encrypt_block);)
 
-_gcry_twofish_arm_decrypt_block:
+.globl C_SYMBOL_NAME(_gcry_twofish_arm_decrypt_block)
+ELF(.type   C_SYMBOL_NAME(_gcry_twofish_arm_decrypt_block),%function;)
+.align 2
+C_SYMBOL_NAME(_gcry_twofish_arm_decrypt_block):
 	/* input:
 	 *	%r0: ctx
 	 *	%r1: dst
@@ -315,7 +316,7 @@ _gcry_twofish_arm_decrypt_block:
 
 	ret_spec_stop;
 	CFI_ENDPROC();
-ELF(.size _gcry_twofish_arm_decrypt_block,.-_gcry_twofish_arm_decrypt_block;)
+ELF(.size C_SYMBOL_NAME(_gcry_twofish_arm_decrypt_block),.-C_SYMBOL_NAME(_gcry_twofish_arm_decrypt_block);)
 
 #endif /*HAVE_COMPATIBLE_GCC_AARCH64_PLATFORM_AS*/
 #endif /*__AARCH64EL__*/
--- a/mpi/aarch64/mpih-add1.S	1697702010.000000000
+++ b/mpi/aarch64/mpih-add1.S	1705148683.922900033
@@ -36,6 +36,7 @@
 
 .globl C_SYMBOL_NAME(_gcry_mpih_add_n)
 ELF(.type  C_SYMBOL_NAME(_gcry_mpih_add_n),%function)
+.align 2
 C_SYMBOL_NAME(_gcry_mpih_add_n):
 	CFI_STARTPROC()
 	and	w5, w3, #3;
--- a/mpi/aarch64/mpih-mul1.S	1697702010.000000000
+++ b/mpi/aarch64/mpih-mul1.S	1705148706.841377554
@@ -36,6 +36,7 @@
 
 .globl C_SYMBOL_NAME(_gcry_mpih_mul_1)
 ELF(.type  C_SYMBOL_NAME(_gcry_mpih_mul_1),%function)
+.align 2
 C_SYMBOL_NAME(_gcry_mpih_mul_1):
 	CFI_STARTPROC()
 	and	w5, w2, #3;
--- a/mpi/aarch64/mpih-mul2.S	1697702010.000000000
+++ b/mpi/aarch64/mpih-mul2.S	1705148710.688835317
@@ -36,6 +36,7 @@
 
 .globl C_SYMBOL_NAME(_gcry_mpih_addmul_1)
 ELF(.type  C_SYMBOL_NAME(_gcry_mpih_addmul_1),%function)
+.align 2
 C_SYMBOL_NAME(_gcry_mpih_addmul_1):
 	CFI_STARTPROC()
 	and	w5, w2, #3;
--- a/mpi/aarch64/mpih-mul3.S	1697702010.000000000
+++ b/mpi/aarch64/mpih-mul3.S	1705148714.890941083
@@ -36,6 +36,7 @@
 
 .globl C_SYMBOL_NAME(_gcry_mpih_submul_1)
 ELF(.type  C_SYMBOL_NAME(_gcry_mpih_submul_1),%function)
+.align 2
 C_SYMBOL_NAME(_gcry_mpih_submul_1):
 	CFI_STARTPROC()
 	and	w5, w2, #3;
--- a/mpi/aarch64/mpih-sub1.S	1697702011.000000000
+++ b/mpi/aarch64/mpih-sub1.S	1705148719.969993113
@@ -36,6 +36,7 @@
 
 .globl C_SYMBOL_NAME(_gcry_mpih_sub_n)
 ELF(.type  C_SYMBOL_NAME(_gcry_mpih_sub_n),%function)
+.align 2
 C_SYMBOL_NAME(_gcry_mpih_sub_n):
 	CFI_STARTPROC()
 	and	w5, w3, #3;
